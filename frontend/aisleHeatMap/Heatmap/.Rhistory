coef(regfit.best,7)
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p, dimnames=list(NULL, paste(1:p-1)))
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1)
for(i in 1:p-1){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean( (data$medv[folds==j]-pred)^2)
}
}
regfit.best=regsubsets(medv~.,data,nvmax=p-1)
coef(regfit.best,7)
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:p)))
regfit.best=regsubsets(medv~.,data,nvmax=p-1)
coef(regfit.best,7)
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:p-1)))
regfit.best=regsubsets(medv~.,data,nvmax=p-1)
coef(regfit.best,7)
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p, dimnames=list(NULL, paste(1:p-1)))
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1)
for(i in 1:p-1){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean( (data$medv[folds==j]-pred)^2)
}
}
regfit.best=regsubsets(medv~.,data,nvmax=p-1)
coef(regfit.best,7)
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p, dimnames=list(NULL, paste(1:p-1)))
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1)
for(i in 1:p){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean( (data$medv[folds==j]-pred)^2)
}
}
regfit.best=regsubsets(medv~.,data,nvmax=p-1)
coef(regfit.best,7)
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:p-1)))
cv.errors=matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:p-1)))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:(p-1))))
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1)
for(i in 1:p-1){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean((data$medv[folds==j]-pred)^2)
}
}
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1)
for(i in 1:(p-1)){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean((data$medv[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors,2,mean)
mean.cv.errors
mean(mean.cv.errors)
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test=(!train)
test.mat=model.matrix(medv~.,data = data[test,])
val.errors=rep(NA,p-1)
for(i in 1:(p-1)){
coefi=coef(reg.fit,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((data$medv[test]-pred)^2)
}
best <- which.min(val.errors)
coef(regfit.best,best)
reg.fit <- regsubsets(medv ~ ., data, nvmax = ncol(Boston), method = "forward")
par(mfrow = c(2,2))
reg.summary <- summary(reg.fit)
plot(reg.summary$rss, type = "l", xlab = "Number of Variables", ylab = "RSS")
plot(reg.summary$adjr2, type = "l", ylab = "Adjr2", xlab = "Number of variables")
max_adjr2 <- which.max(reg.summary$adjr2)
points(max_adjr2, reg.summary$adjr2[max_adjr2], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
min_cp <- which.min(reg.summary$cp)
points(min_cp , reg.summary$cp[min_cp], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$bic, xlab= "Number of variables", ylab = "BIC", type="l")
min_bic <- which.min(reg.summary$bic)
points(min_bic, reg.summary$bic[min_bic], col = "Red", pch=20, cex=2)
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)  ## Choosing number of predictors
test=(!train)
test.mat=model.matrix(medv~.,data = data[test,])
val.errors=rep(NA,p-1)
for(i in 1:(p-1)){
coefi=coef(reg.fit,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((data$medv[test]-pred)^2)
}
best <- which.min(val.errors)
coef(regfit.best,best)
predict.regsubsets=function(object,newdata,id){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:(p-1))))
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1, method = "forward")
for(i in 1:(p-1)){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean((data$medv[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors,2,mean)
mean(mean.cv.errors)
x = model.matrix(medv~.,data)[,-1]
y = data$medv
grid = 10^seq(-1,100, length = 10)
ridge.mod = glmnet(x,y, alpha =0, lambda = grid, standardize=TRUE)
n = nrow(data)
p = ncol(data)
k=10
set.seed(1)
train <- sample(rep(1:k, length = n))
cv.out = cv.glmnet(x[train,],y[train], alpha = 0, nfolds = k)
bestlam = cv.out$lambda.min
bestlam
ridge.pred = predict(ridge.mod, s=bestlam, newx x[test,], exact = T, x= x[train,], y=y[train], thresh = 1e-16)
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,], exact = T, x= x[train,], y=y[train], thresh = 1e-16)
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,], exact=TRUE, x= x[train,], y=y[train], thresh = 1e-16)
ridge.pred
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,])
x = model.matrix(medv~.,data)[,-1]
y = data$medv
grid = 10^seq(-1,100, length = 10)
ridge.mod = glmnet(x,y, alpha =0, lambda = grid, standardize=TRUE)
k=10
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
cv.out = cv.glmnet(x[train,],y[train], alpha = 0, nfolds = k)
bestlam = cv.out$lambda.min
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,])
x = model.matrix(medv~.,data)[,-1]
y = data$medv
grid = 10^seq(-1,100, length = 10)
ridge.mod = glmnet(x[train,],y[train], alpha =0, lambda = grid, standardize=TRUE, trhesh = 1e-12)
k=10
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
cv.out = cv.glmnet(x[train,],y[train], alpha = 0, nfolds = k)
bestlam = cv.out$lambda.min
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,])
x = model.matrix(medv~.,data)[,-1]
y = data$medv
grid = 10^seq(-1,100, length = 10)
ridge.mod = glmnet(x[train,],y[train], alpha =0, lambda = grid, standardize=TRUE, thresh = 1e-12)
k=10
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
cv.out = cv.glmnet(x[train,],y[train], alpha = 0, nfolds = k)
bestlam = cv.out$lambda.min
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,])
ridge.pred
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
# Ridge Regression
library(glmnet)
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[,50]
sqrt(sum(coef(ridge.mod)[-1,50]^2))
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2))
predict(ridge.mod,s=50,type="coefficients")[1:20,]
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train])
mean((ridge.pred-y.test)^2)
my.lm=lm(y~.,subset=train,data=data.frame(y,x))
lm.pred = predict(my.lm,newdata=data.frame(y,x)[test,])
mean((lm.pred-y.test)^2)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T,x=x[train,],y=y[train],thresh=1e-16)
mean((ridge.pred-y.test)^2)
#predict(ridge.mod,s=0,exact=T,type="coefficients", x=x[train,],y=y[train])[1:20,]
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0,nfolds=10)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
ridge.pred
x = model.matrix(medv~.,data)[,-1]
y = data$medv
grid=10^seq(10,-2,length=100)
ridge.mod = glmnet(x[train,],y[train], alpha =0, lambda = grid, standardize=TRUE, thresh = 1e-12)
k=10
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
cv.out = cv.glmnet(x[train,],y[train], alpha = 0, nfolds = k)
bestlam = cv.out$lambda.min
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,])
ridge.pred
mean((ridge.pred - y[test])^2)
library(pls)
pcr.fit <- pcr(medv~. ,data, scale= TRUE, validation = "cv", subset = train)
### PCR
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
pcr.fit <- pcr(medv~.,data, scale= TRUE, validation = "cv", subset = train)
pcr.fit <- pcr(medv~.,data = data, scale= TRUE, validation = "cv", subset = train)
pcr(medv~.,data = data, scale= TRUE, validation = "CV", subset = train)
pcr.fit <- pcr(medv~.,data = data, scale= TRUE, validation = "CV", subset = train)
names(pcr.fit)
pcr.fit$coefficients
validationplot(pcc.fit, val.type = "MSEP")
pcr.fit <- pcr(medv~.,data = data, scale= TRUE, validation = "CV", subset = train)
Validationplot(pcr.fit, val.type = "MSEP")
pcr.fit <- pcr(medv~.,data = data, scale= TRUE, validation = "CV", subset = train)
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred <- predict(pcr.fit, x[test,], ncomp = 5)
mean((pcr.pred-y[test])^2)
x = model.matrix(medv~.,data)[,-1]
y = data$medv
grid=10^seq(10,-2,length=100)
ridge.mod = glmnet(x[train,],y[train], alpha =0, lambda = grid, standardize=TRUE, thresh = 1e-12)
k=10
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
cv.out = cv.glmnet(x[train,],y[train], alpha = 0, nfolds = k)
bestlam = cv.out$lambda.min
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,])
mean((ridge.pred - y[test])^2)
reg.fit <- regsubsets(medv ~ ., data, nvmax = ncol(Boston), method = "forward")
par(mfrow = c(2,2))
reg.summary <- summary(reg.fit)
plot(reg.summary$rss, type = "l", xlab = "Number of Variables", ylab = "RSS")
plot(reg.summary$adjr2, type = "l", ylab = "Adjr2", xlab = "Number of variables")
max_adjr2 <- which.max(reg.summary$adjr2)
points(max_adjr2, reg.summary$adjr2[max_adjr2], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
min_cp <- which.min(reg.summary$cp)
points(min_cp , reg.summary$cp[min_cp], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$bic, xlab= "Number of variables", ylab = "BIC", type="l")
min_bic <- which.min(reg.summary$bic)
points(min_bic, reg.summary$bic[min_bic], col = "Red", pch=20, cex=2)
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)  ## Choosing number of predictors
test=(!train)
test.mat=model.matrix(medv~.,data = data[test,])
val.errors=rep(NA,p-1)
for(i in 1:(p-1)){
coefi=coef(reg.fit,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((data$medv[test]-pred)^2)
}
best <- which.min(val.errors)
coef(regfit.best,best)
predict.regsubsets=function(object,newdata,id){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:(p-1))))
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1, method = "forward")
for(i in 1:(p-1)){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean((data$medv[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors,2,mean)
mean(mean.cv.errors)
coef(regfit.best,best)
best <- which.min(val.errors)
coef(reg.fit,best)
reg.fit <- regsubsets(medv ~ ., data, nvmax = ncol(Boston), method = "forward")
par(mfrow = c(2,2))
reg.summary <- summary(reg.fit)
plot(reg.summary$rss, type = "l", xlab = "Number of Variables", ylab = "RSS")
plot(reg.summary$adjr2, type = "l", ylab = "Adjr2", xlab = "Number of variables")
max_adjr2 <- which.max(reg.summary$adjr2)
points(max_adjr2, reg.summary$adjr2[max_adjr2], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
min_cp <- which.min(reg.summary$cp)
points(min_cp , reg.summary$cp[min_cp], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$bic, xlab= "Number of variables", ylab = "BIC", type="l")
min_bic <- which.min(reg.summary$bic)
points(min_bic, reg.summary$bic[min_bic], col = "Red", pch=20, cex=2)
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)  ## Choosing number of predictors
test=(!train)
test.mat=model.matrix(medv~.,data = data[test,])
val.errors=rep(NA,p-1)
for(i in 1:(p-1)){
coefi=coef(reg.fit,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((data$medv[test]-pred)^2)
}
best <- which.min(val.errors)
coef(reg.fit,best)
predict.regsubsets=function(object,newdata,id){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:(p-1))))
for(j in 1:k){
best.fit=regsubsets(medv~.,data=data[folds!=j,],nvmax=p-1, method = "forward")
for(i in 1:(p-1)){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean((data$medv[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors,2,mean)
mean(mean.cv.errors)
?Boston
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(leaps)
library(glmnet)
library(pls)
data <- (ISLR2::Boston)
n <- nrow(Boston)
p <- ncol(Boston)
set.seed(1)
reg.fit <- regsubsets(crim ~ ., data, nvmax = ncol(Boston), method = "forward")
par(mfrow = c(2,2))
reg.summary <- summary(reg.fit)
plot(reg.summary$rss, type = "l", xlab = "Number of Variables", ylab = "RSS")
plot(reg.summary$adjr2, type = "l", ylab = "Adjr2", xlab = "Number of variables")
max_adjr2 <- which.max(reg.summary$adjr2)
points(max_adjr2, reg.summary$adjr2[max_adjr2], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$cp, xlab = "Number of Variables", ylab = "Cp", type = "l")
min_cp <- which.min(reg.summary$cp)
points(min_cp , reg.summary$cp[min_cp], col = "Red", cex = 2, pch = 20 )
plot(reg.summary$bic, xlab= "Number of variables", ylab = "BIC", type="l")
min_bic <- which.min(reg.summary$bic)
points(min_bic, reg.summary$bic[min_bic], col = "Red", pch=20, cex=2)
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)  ## Choosing number of predictors
test=(!train)
test.mat=model.matrix(crim~.,data = data[test,])
val.errors=rep(NA,p-1)
for(i in 1:(p-1)){
coefi=coef(reg.fit,id=i)
pred=test.mat[,names(coefi)]%*%coefi
val.errors[i]=mean((data$crim[test]-pred)^2)
}
best <- which.min(val.errors)
coef(reg.fit,best)
predict.regsubsets=function(object,newdata,id){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k=10
set.seed(1)
folds=sample(rep(1:k,length=n))
cv.errors=matrix(NA,k,p-1, dimnames=list(NULL, paste(1:(p-1))))
for(j in 1:k){
best.fit=regsubsets(crim~.,data=data[folds!=j,],nvmax=p-1, method = "forward")
for(i in 1:(p-1)){
pred=predict(best.fit,data[folds==j,],id=i)
cv.errors[j,i]=mean((data$crim[folds==j]-pred)^2)
}
}
mean.cv.errors=apply(cv.errors,2,mean)
mean(mean.cv.errors)
x = model.matrix(crim~.,data)[,-1]
y = data$crim
grid=10^seq(10,-2,length=100)
ridge.mod = glmnet(x[train,],y[train], alpha =0, lambda = grid, standardize=TRUE, thresh = 1e-12)
k=10
set.seed(1)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
cv.out = cv.glmnet(x[train,],y[train], alpha = 0, nfolds = k)
bestlam = cv.out$lambda.min
ridge.pred = predict(ridge.mod, s=bestlam, newx=x[test,])
mean((ridge.pred - y[test])^2)
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
pcr.fit <- pcr(crim~.,data = data, scale= TRUE, validation = "CV", subset = train)
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred <- predict(pcr.fit, x[test,], ncomp = 5)
mean((pcr.pred-y[test])^2)
summary(pcr.fit)
summary(pcr.fit)
summary(pcr.fit)$coef
coef(summary(pcr.fit))
names(summary(pcr.fit))
train=sample(c(TRUE,FALSE), n,rep=TRUE)
test = (!train)
pcr.fit <- pcr(crim~.,data = data, scale= TRUE, validation = "CV", subset = train)
validationplot(pcr.fit, val.type = "MSEP")
pcr.fit <- pcr(crim~., data = data, scake = TRUE, ncomp = 5)
pcr.pred <- predict(pcr.fit, x[test,], ncomp = 5)
mean((pcr.pred-y[test])^2)
coef(reg.fit,best)
best
shiny::runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/HeatMap')
date_options <- unique(data$date)
date_options
data$date
data
library(shiny)
library(dygraphs)
library(rgdal)
library(flexdashboard)
library(tidyverse)
library(plotly)
library(jsonlite)
library(DT)
library(jsonlite)
library(dplyr)
##add fake information here first
data = readLines("../UpdatedFakeData.json")
setwd("C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/HeatMap")
library(shiny)
library(dygraphs)
library(rgdal)
library(flexdashboard)
library(tidyverse)
library(plotly)
library(jsonlite)
library(DT)
library(jsonlite)
library(dplyr)
##add fake information here first
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), camera = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, camera = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
colnames(data) = c("id", "aisle","time","date")
## Add count TRY ONLY
data = cbind(data, count = sample(c(1:10),nrow(data),replace=TRUE))
## REAL ADD CUSTOMER COUNT
#data = data %>% group_by(date,time, aisle) %>% count()
data <- data %>%
group_by(aisle, date, time) %>%
summarise(count = sum(count)) %>%
arrange(by_group=TRUE) %>%
ungroup()
time_options <- c("12am", paste0(seq(1,11),"am"), paste0(seq(1,11),"pm"))
date_options <- unique(data$date)
data
head(data)
runApp()
date_options
date_options[1]
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
