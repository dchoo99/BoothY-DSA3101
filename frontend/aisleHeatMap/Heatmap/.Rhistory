attach(data)
error <- rep(0,poly)
for (j in 1:poly) {        ## for polynomial
ith_fold_error <- rep(0,k)    ## record error for each iteration of folds
for (i in 1:k) {  ## k-folds
train <- (groups==i)
lm.fit <- lm(mpg~poly(horsepower,j), data = data, subset = train)
ith_fold_error[i] <- mean((mpg-predict(lm.fit,Auto))[-train]^2)   ## Coallate error per fold
}
error[j] <- mean(ith_fold_error)         ## Error of that polynomial = mean(ith_fold_error)
}
return (error)
}
set.seed(seed)
n <- nrow(data)
train_size <- floor(n/k)
groups <- sample(rep(1:k, train_size), n)
data <- cbind(data,groups)
error
k_foldCV(Auto, 10, 17, 10)
k_foldCV = function(data, k, seed, poly) {
set.seed(seed)
n <- nrow(data)
train_size <- floor(n/k)
groups <- sample(rep(1:k, train_size), n, replace = TRUE)
data <- cbind(data,groups)
attach(data)
error <- rep(0,poly)
for (j in 1:poly) {        ## for polynomial
ith_fold_error <- rep(0,k)    ## record error for each iteration of folds
for (i in 1:k) {  ## k-folds
train <- (groups==i)
lm.fit <- lm(mpg~poly(horsepower,j), data = data, subset = train)
ith_fold_error[i] <- mean((mpg-predict(lm.fit,Auto))[-train]^2)   ## Coallate error per fold
}
error[j] <- mean(ith_fold_error)         ## Error of that polynomial = mean(ith_fold_error)
}
return (error)
}
k_foldCV(Auto, 10, 17, 10)
k_foldCV = function(data, k, seed, poly) {
set.seed(seed)
n <- nrow(data)
train_size <- floor(n/k)
groups <- sample(rep(1:k, train_size), n, replace = TRUE)
data <- cbind(data,groups)
attach(data)
error <- rep(0,poly)
for (j in 1:poly) {        ## for polynomial
ith_fold_error <- rep(0,k)    ## record error for each iteration of folds
for (i in 1:k) {  ## k-folds
train <- (groups !=i)
lm.fit <- lm(mpg~poly(horsepower,j), data = data, subset = train)
ith_fold_error[i] <- mean((mpg-predict(lm.fit,Auto))[-train]^2)   ## Coallate error per fold
}
error[j] <- mean(ith_fold_error)         ## Error of that polynomial = mean(ith_fold_error)
}
return (error)
}
k_foldCV(Auto, 10, 17, 10)
library(boot)
glm.fit=glm(mpg~horsepower,data=Auto)
cv.err=cv.glm(Auto,glm.fit)
cv.err$delta
cv.error=rep(0,5)
for (i in 1:5){
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10){
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
cv.error.10
k_foldCV(Auto, 10, 17, 10)
Lab <- cv.error.10
Lab <- cv.error.10
Mine <- k_foldCV(Auto, 10, 17, 10)
cbind(Mine, Lab)
Final <- cbind(Mine, Lab)
Final
?glm
?cb.glm
?cv.glm
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(stats)
library(boot)
k_foldCV = function(data, k, seed, poly) {
set.seed(seed)
n <- nrow(data)
train_size <- floor(n/k)
groups <- sample(rep(1:k, train_size), n, replace = TRUE)  ## rep(1:k, train_size) generates each number from 1:k train_size times
data <- cbind(data,groups)       ## Sample then picks from this list until it hits n values, with replacement
## Then we bind it together
attach(data)
error <- rep(0,poly)
for (j in 1:poly) {        ## for polynomial
ith_fold_error <- rep(0,k)    ## record error for each iteration of folds
for (i in 1:k) {  ## k-folds
train <- (groups !=i)
lm.fit <- lm(mpg~poly(horsepower,j), data = data, subset = train)
ith_fold_error[i] <- mean((mpg-predict(lm.fit,Auto))[-train]^2)   ## Coallate error per fold
}
error[j] <- mean(ith_fold_error)         ## Error of that polynomial = mean(ith_fold_error)
}
return (error)
}
Mine <- k_foldCV(Auto, 10, 1, 10)
set.seed(1)
cv.error.10=rep(0,10)
for (i in 1:10){
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
Lab <- cv.error.10
cbind(Mine, Lab)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(stats)
library(boot)
k_foldCV = function(data, k, poly) {
n <- nrow(data)
train_size <- floor(n/k)
groups <- sample(rep(1:k, train_size), n, replace = TRUE)  ## rep(1:k, train_size) generates each number from 1:k train_size times
data <- cbind(data,groups)       ## Sample then picks from this list until it hits n values, with replacement
## Then we bind it together
attach(data)
error <- rep(0,poly)
for (j in 1:poly) {        ## for polynomial
ith_fold_error <- rep(0,k)    ## record error for each iteration of folds
for (i in 1:k) {  ## k-folds
train <- (groups !=i)
lm.fit <- lm(mpg~poly(horsepower,j), data = data, subset = train)
ith_fold_error[i] <- mean((mpg-predict(lm.fit,Auto))[-train]^2)   ## Coallate error per fold
}
error[j] <- mean(ith_fold_error)         ## Error of that polynomial = mean(ith_fold_error)
}
return (error)
}
Mine <- k_foldCV(Auto, 10, 10)
set.seed(1)
Mine <- k_foldCV(Auto, 10,10)
cv.error.10=rep(0,10)
for (i in 1:10){
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
Lab <- cv.error.10
cbind(Mine, Lab)
cv.error.10=rep(0,10)
for (i in 1:10){
glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
}
Lab <- cv.error.10
cbind(Mine, Lab)
install.packages("reveal.js")
install.packages("revealjs")
# install from CRAN
install.packages('xaringan')
# or GitHub
devtools::install_github('yihui/xaringan')
install.packages("devtools")
install.packages("devtools")
shiny::runApp('School/Education/Y3S1/DSA3101/Shiny/DSA3101')
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss.summary$rss, type="l")
reg.ss <- regsubsets(y~., data, nvmax = 10)
## Best subset selection
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss.summary$rss, type="l")
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
x <- rnorm(100)
eps <- rnorm(100)
y <- 1 + 1*x + 1*x^2 + 1*x^3 + eps
X <- c()
for (i in 1:10) {
cur <- x^i
X <- cbind(X,cur)
}
names = c()
for (i in 1:10) {
cur = paste0("x",i)
names = append(names, cur)
}
colnames(X) <- names
# c)
reg.ss <- regsubsets(y~., data, nvmax = 10)
## Best subset selection
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss.summary$rss, type="l")
data <- as.data.frame(cbind(X,y))
reg.ss <- regsubsets(y~., data, nvmax = 10)
regsubsets(y~., data, nvmax = 10)
library(leaps)
reg.ss <- regsubsets(y~., data, nvmax = 10)
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss.summary$r2, type="l")
plot(reg.ss.summary$cp, type="l")
plot(reg.ss.summary$bic, type="l")
dev.off()
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss, scale="r2")
plot(reg.ss.summary$cp, type="l")
plot(reg.ss.summary$bic, type="l")
reg.ss.summary
index(min(reg.ss.summary$bic))
min(reg.ss.summary$bic)
reg.ss.summary$bic
reg.ss.summary$Index
reg.ss.summary$index
which.min(reg.ss.summary$bic)
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss, scale="r2")
plot(reg.ss.summary$cp, type="l")
plot(reg.ss.summary$bic, type="l")
index.ss <- which.min(reg.ss.summary$bic)
which.min(reg.ss.summary$cp)
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss, scale="r2")
plot(reg.ss.summary$cp, type="l")
plot(reg.ss.summary$bic, type="l")
index.ss <- which.min(reg.ss.summary$bic)
## Using which.min(reg.ss.summary$cp) gives same result
points(min(Reg.ss.summary$bic), index.ss, col="Red")
points(min(reg.ss.summary$bic), index.ss, col="Red")
dev.off()
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss, scale="r2")
plot(reg.ss.summary$cp, type="l")
plot(reg.ss.summary$bic, type="l")
index.ss <- which.min(reg.ss.summary$bic)
## Using which.min(reg.ss.summary$cp) gives same result
points(min(reg.ss.summary$bic), index.ss, col="Red")
## Best subset selection
reg.ss.summary <- summary(reg.ss)
par(mfrow=c(2,2))
plot(reg.ss, scale="r2")
plot(reg.ss.summary$cp, type="l")
points(min(reg.ss.summary$bic), index.ss, col="Red")
plot(reg.ss.summary$bic, type="l")
points(min(reg.ss.summary$bic), index.ss, col="Red")
index.ss <- which.min(reg.ss.summary$bic)
## Using which.min(reg.ss.summary$cp) gives same result
points(min(reg.ss.summary$bic), index.ss, col="Red")
points(index.ss, reg.ss.summary$cp[index])
points(index.ss, reg.ss.summary$cp[index.ss])
coef(reg.ss, index.ss)
reg.for <- regsubsets(y~., data, nvmax = 10, method = "forward")
par(mfrow=c(2,2))
reg.for <- regsubsets(y~., data, nvmax = 10, method = "forward")
reg.for.summary <- summary(reg.for)
par(mfrow=c(2,2))
plot(reg.for, scale="r2")
plot(reg.for.summary$cp, type="l")
plot(reg.for.summary$bic, type="l")
plot(reg.for.summary$bic, type="l")
reg.for <- regsubsets(y~., data, nvmax = 10, method = "forward")
reg.for.summary <- summary(reg.for)
par(mfrow=c(2,2))
plot(reg.for, scale="r2")
plot(reg.for.summary$cp, type="l")
plot(reg.for.summary$bic, type="l")
coef(reg.ss, index.ss)
index.for <- which.min(reg.for.summary$bic) ## Using which.min(reg.for.summary$cp) gives same result
coef(reg.for, index.for)
reg.for
which.min(reg.for.summary$cp)
index.for <- which.min(reg.for.summary$bic)
coef(reg.for, index.for)
coef(reg.ss, index.ss)
reg.back <- regsubsets(y~., data, nvmax = 10, method = "backward")
reg.back.summary <- summary(reg.back)
par(mfrow=c(2,2))
plot(reg.back, scale="r2")
plot(reg.back.summary$cp, type="l")
plot(reg.back.summary$bic, type="l")
index.back <- which.min(reg.back.summary$bic) ## Using which.min(reg.for.summary$cp) gives same result
coef(reg.back, index.back)
index.back
which.min(reg.back.summary$cp)
which.min(reg.back.summary$bic
)
Sys.which("make")
write('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', file = "~/.Renviron", append = TRUE)
Sys.which("make")
Sys.which("make")
Sys.which("make")
install.packages("Sys.time")
Sys.which("make")
Sys.which("make")
Sys.Date()
Sys.Time()
Sys.time()
curdate <- Sys.Date()
date_options <- seq(curdate, by = "day", length.out = 7)
shiny::runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
paste0(c(1:23))
paste0(c(1:23),hours)
paste0(c(1:23),"hours")
runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
seq(1:12)+seq(12:1)
seq(12:1)
?seq
seq(12,1)
seq(1,12),seq(12,1)
c(seq(1,12),seq(1,12))
c(paste0(seq(1,12),"am"),seq(1,12))
c("12am", paste0(seq(1,11),"am"), paste0(seq(1,11),"pm"),"12am")
c("12am", paste0(seq(1,11),"am"), paste0(seq(1,11),"pm"))
runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
install.packages("ComplexHeatmap")
install.packages("installr")
library(installr)
updateR()
install.packages("installr")
library(installr)
updateR()
install.packages("installr")
library(installr)
updateR()
shiny::runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
runApp('C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap')
data
##add fake information here first
data = readLines("../UpdatedFakeData.json")
setwd("C:/Users/Zoe Lua/dsa3101-2210-03-priv/frontend/aisleHeatMap/Realheatmap")
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), camera = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, camera = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
## Add count TRY ONLY
data = cbind(data, count = sample(c(1:10),nrow(data),replace=TRUE), cp = sample(c(1:20),nrow(data),replace=TRUE))
data <- data %>%
group_by(camera, date, time, cp) %>%
summarise(count = sum(count)) %>%
arrange(by_group=TRUE) %>%
ungroup()
View(data)
runApp()
rlang::last_error()
data
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), aisle = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, aisle = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
data
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), aisle = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, aisle = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
data$head)
str(data)
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), aisle = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, aisle = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
data
str(data)
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), aisle = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, aisle = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
data
str(data)
runApp()
##add fake information here first
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), camera = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, camera = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
## Add count TRY ONLY
data = cbind(data, count = sample(c(1:10),nrow(data),replace=TRUE), cp = sample(c(1:20),nrow(data),replace=TRUE))
data
##add fake information here first
data = readLines("../UpdatedFakeData.json")
fake_json = lapply(data, fromJSON)
data = data.frame(id = numeric(0), camera = numeric(0), time = character(0))
empty_table = data.frame()
for (i in 1:length(fake_json)) {
idx = i
occ = fake_json[[i]]$occurrence
temp  = data.frame(id = idx, camera = occ[1], time = occ[2])
temp$time = as.POSIXct(strptime(temp$time, format = "%Y-%m-%d %H:%M:%S"))
temp$date = as.Date(temp$time)
temp$time = format(as.POSIXct(temp$time), format = "%H") ## Just extract hours
data = rbind(data, temp)
}
colnames(data) = c("id", "aisle","time","date")
## Add count TRY ONLY
data = cbind(data, count = sample(c(1:10),nrow(data),replace=TRUE), cp = sample(c(1:20),nrow(data),replace=TRUE))
data
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
cur_date <- "2022-10-18"
cur_time <- "09"
subset <- data %>% filter(date == cur_date & time == cur_time ) %>% select(camera, cp, count)
cur_date <- "2022-10-18"
cur_time <- "09"
subset <- data %>% filter(date == cur_date & time == cur_time )
ifelse(subset==NULL, TRUE, FALSE)
cur_date <- "2022-10-18"
cur_time <- "09"
subset <- data %>% filter(date == cur_date & time == cur_time )
ifelse(subset==NULL, 1, 0)
cur_date <- "2022-10-18"
cur_time <- "09"
subset <- data %>% filter(date == cur_date & time == cur_time )
ifelse(length(subset) ==0 , 1, 0)
runApp()
cur_date <- "2022-10-18"
cur_time <- "09"
subset <- data %>% filter(date == cur_date & time == cur_time )
ifelse(length(subset) ==0 , 1, 0)
cur_date <- "2022-10-18"
cur_time <- "09"
subset <- data %>% filter(date == cur_date & time == cur_time )
ifelse(nrow(subset) ==0 , 1, 0)
runApp()
runApp()
runApp()
runApp()
rep(1,10)
runApp()
runApp()
mean(data$count)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
