{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the images from the entry camera into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siyin\\OneDrive\\Documents\\SiYing\\University\\Year 3\\DSA3101\\Code\\dsa3101-2210-03-priv\\backend\\template_matching.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         num\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         db\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m:imgs, \u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m:shoe_id,\u001b[39m'\u001b[39m\u001b[39mnumber\u001b[39m\u001b[39m'\u001b[39m:num})\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(depth(imgs))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'depth' is not defined"
     ]
    }
   ],
   "source": [
    "# image database (contains images taken by the entry camera)\n",
    "db = []\n",
    "\n",
    "folder_dir = 'base_photos'    \n",
    "images = Path(folder_dir).glob('*.jpg')\n",
    "gen = ImageDataGenerator(rotation_range=60, horizontal_flip = True) #change accordingly\n",
    "\n",
    "for image in images:\n",
    "    tmp = str(image)[len(folder_dir)+1:][:-4].split(\"-\")\n",
    "    shoe_id = int(tmp[0])\n",
    "    num = int(tmp[1])\n",
    "    img = cv.imread(str(image))\n",
    "    db.append({'image':img, 'id':shoe_id, 'number':num})\n",
    "    #image augmentation\n",
    "    original_image = np.expand_dims(img,0) #expand dimensions for compatibility\n",
    "    aug_iter = gen.flow(original_image, batch_size = 10) #to generate 10 augmented images from original image\n",
    "    aug_images = [next(aug_iter)[0].astype(np.uint8) for i in range(10)]\n",
    "    for i in aug_images\n",
    "        num+=1\n",
    "        db.append({'image':i, 'id':shoe_id,'number':num})\n",
    "        \n",
    "# to display the 6th picture in the photos directory\n",
    "# cv.imshow('test', db[5]['image'])\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, I only saved the original pictures into the db. I haven't done image augmentation (eg. flip, rotate) on them. Moving on, we should add the augmented images into the db, with the same `id` but with a diff `number`\n",
    "\n",
    "Also, the names of the images in `base_photos` is saved such that the number before the - is the id number, while the number after the - is just to show which photo of the id is this. For example, `2-3.jpg` means this shoe is id 2 and this photo is the 3rd photo of id 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Template Matching method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the ids of shoes in folder `to_retrieve_ids`. Note that in the folder, only `1.jpg` is exactly the same as picture `4-1.jpg` in `base_photos`. Other pictures in `to_retrieve_ids` are not exact replicate of pictures in `base_photos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\templmatch.cpp:1164: error: (-215:Assertion failed) (depth == CV_8U || depth == CV_32F) && type == _templ.type() && _img.dims() <= 2 in function 'cv::matchTemplate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siyin\\OneDrive\\Documents\\SiYing\\University\\Year 3\\DSA3101\\Code\\dsa3101-2210-03-priv\\backend\\template_matching.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# perform match operation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m db:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     res \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49mmatchTemplate(item[\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m], template, cv\u001b[39m.\u001b[39;49mTM_CCOEFF_NORMED)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(res \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siyin/OneDrive/Documents/SiYing/University/Year%203/DSA3101/Code/dsa3101-2210-03-priv/backend/template_matching.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(loc[\u001b[39m0\u001b[39m])\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(loc[\u001b[39m1\u001b[39m])\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m):    \u001b[39m# if there's a match\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\templmatch.cpp:1164: error: (-215:Assertion failed) (depth == CV_8U || depth == CV_32F) && type == _templ.type() && _img.dims() <= 2 in function 'cv::matchTemplate'\n"
     ]
    }
   ],
   "source": [
    "folder_dir = 'to_retrieve_ids'\n",
    "images = Path(folder_dir).glob('*.jpg')\n",
    "\n",
    "actual_ids = [4, 4, 2, 3]\n",
    "identified = []    # stores result from template matching\n",
    "\n",
    "for image in images:\n",
    "    template = cv.imread(str(image), cv.IMREAD_COLOR)\n",
    "    threshold = 0.70   # set threshold; high (ie. 1) means \"more strict\"\n",
    "    tmp = []    # stores detected ids for this shoe; if empty means no id is assigned to this shoe\n",
    "    \n",
    "    # perform match operation\n",
    "    for item in db:\n",
    "        res = cv.matchTemplate(item['image'], template, cv.TM_CCOEFF_NORMED)\n",
    "        loc = np.where(res >= threshold)\n",
    "        if (len(loc[0])!=0 and len(loc[1])!=0):    # if there's a match\n",
    "            tmp.append(item['id'])\n",
    "            \n",
    "    identified.append(tmp)\n",
    "    \n",
    "identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an interpretation of the variable `identified`:\n",
    "\n",
    "For this threshold, `1.jpg` in `to_retrieve_ids` is correctly assigned to id 4, but is mistaken to be id 2 as well. Same for `2.jpg` which is mistaken to be id 1 and id 2. The last element of `identified` is an empty list, which means that the algorithm failed to identify that `4.jpg` is actually id 3.\n",
    "\n",
    "Note: after changing the threshold to 0.85, ids are correctly assigned to `1.jpg` and `2.jpg`. But the algorithm failed to recognise that `3.jpg` is actually id 2 and `4.jpg` is id 3.\n",
    "\n",
    "We shall see if it will improve with image augmentation + background removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to visualize bounding boxes\n",
    "a = cv.imread('base_photos/4-2.jpg')     # can change\n",
    "b = cv.imread('to_retrieve_ids/1.jpg', cv.IMREAD_COLOR)    # can change\n",
    "\n",
    "res = cv.matchTemplate(a, b, cv.TM_CCOEFF_NORMED)\n",
    "w, h = b.shape[1], b.shape[0]\n",
    "threshold = 0.7\n",
    "loc = np.where(res >= threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv.rectangle(a, pt, (pt[0] + w, pt[1] + h), (0, 255, 255), 2)\n",
    "cv.imshow('Detected', a)\n",
    "cv.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99d7e9470b487d8ff586e047a6715993cfcc0e16b723e7c771ed5eb775a58975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
